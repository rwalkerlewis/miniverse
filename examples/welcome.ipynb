{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to Miniverse\n",
    "\n",
    "**Build emergent agent-based simulations powered by LLMs.**\n",
    "\n",
    "This notebook shows you what Miniverse does through a simple Mars habitat simulation. You'll see:\n",
    "\n",
    "- **3 agents** (Commander, Engineer, Scientist) coordinate on Mars base operations\n",
    "- **LLM-driven decisions** - agents plan, communicate, and adapt\n",
    "- **Emergent behavior** - watch coordination emerge from individual goals\n",
    "- **Full observability** - inspect plans, memories, and reasoning\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before running this notebook, configure your LLM provider:\n",
    "\n",
    "```bash\n",
    "export LLM_PROVIDER=openai\n",
    "export LLM_MODEL=gpt-5-nano\n",
    "export OPENAI_API_KEY=your_key\n",
    "```\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import and Check Setup\n",
    "\n",
    "First, let's verify your LLM configuration is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LLM Configuration ===\n",
      "‚úÖ Provider: openai\n",
      "‚úÖ Model: gpt-5-nano\n",
      "‚úÖ API Key: Set\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import asyncio\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# Check LLM configuration\n",
    "provider = os.getenv('LLM_PROVIDER')\n",
    "model = os.getenv('LLM_MODEL')\n",
    "\n",
    "print('=== LLM Configuration ===')\n",
    "if not provider or not model:\n",
    "    print('‚ùå LLM not configured')\n",
    "    print('   Set LLM_PROVIDER, LLM_MODEL, and API key environment variables')\n",
    "else:\n",
    "    print(f'‚úÖ Provider: {provider}')\n",
    "    print(f'‚úÖ Model: {model}')\n",
    "    print(f'‚úÖ API Key: {\"Set\" if os.getenv(f\"{provider.upper()}_API_KEY\") else \"Missing\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Import Miniverse Components\n",
    "\n",
    "Miniverse has a modular architecture:\n",
    "\n",
    "- **WorldState** - Tracks resources, agents, environment\n",
    "- **AgentProfile** - Defines agent identity, goals, relationships\n",
    "- **SimulationRules** - Your custom physics (deterministic updates)\n",
    "- **AgentCognition** - How agents think (executor, planner, memory)\n",
    "- **Orchestrator** - Coordinates everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Miniverse components imported\n",
      "\n",
      "Key classes available:\n",
      "   ‚Ä¢ WorldState - simulation state container\n",
      "   ‚Ä¢ AgentProfile - agent identity and goals\n",
      "   ‚Ä¢ SimulationRules - custom physics interface\n",
      "   ‚Ä¢ AgentCognition - LLM-powered decision making\n",
      "   ‚Ä¢ Orchestrator - main simulation coordinator\n"
     ]
    }
   ],
   "source": [
    "from miniverse import (\n",
    "    Orchestrator, AgentProfile, AgentStatus, WorldState,\n",
    "    ResourceState, EnvironmentState, SimulationRules,\n",
    "    Stat, AgentAction\n",
    ")\n",
    "from miniverse.cognition import AgentCognition, LLMExecutor, LLMPlanner, Scratchpad\n",
    "\n",
    "print('‚úÖ Miniverse components imported')\n",
    "print('\\nKey classes available:')\n",
    "print('   ‚Ä¢ WorldState - simulation state container')\n",
    "print('   ‚Ä¢ AgentProfile - agent identity and goals')\n",
    "print('   ‚Ä¢ SimulationRules - custom physics interface')\n",
    "print('   ‚Ä¢ AgentCognition - LLM-powered decision making')\n",
    "print('   ‚Ä¢ Orchestrator - main simulation coordinator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define the Physics\n",
    "\n",
    "Miniverse separates **deterministic physics** from **emergent cognition**.\n",
    "\n",
    "Your physics rules define:\n",
    "- How resources change each tick\n",
    "- How agent actions affect the world\n",
    "- Natural degradation and constraints\n",
    "\n",
    "Agents then make decisions using LLMs within this physics framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Mars habitat physics defined\n",
      "\n",
      "Physics rules:\n",
      "   Action effects:\n",
      "   ‚Ä¢ generate_power: +15 kWh\n",
      "   ‚Ä¢ research: +10% progress, -8 kWh\n",
      "   ‚Ä¢ maintenance: +12% system health\n",
      "\n",
      "   Natural degradation:\n",
      "   ‚Ä¢ Power: -5 kWh per tick (base consumption)\n",
      "   ‚Ä¢ System health: -3% per tick (wear and tear)\n"
     ]
    }
   ],
   "source": [
    "class MarsHabitatRules(SimulationRules):\n",
    "    \"\"\"Simple Mars base: manage power, conduct research, handle maintenance.\"\"\"\n",
    "    \n",
    "    def apply_tick(self, state, tick):\n",
    "        updated = state.model_copy(deep=True)\n",
    "        \n",
    "        # Get current resources\n",
    "        power = updated.resources.get_metric('power', default=100, unit='kWh')\n",
    "        research = updated.resources.get_metric('research_progress', default=0, unit='%')\n",
    "        maintenance = updated.resources.get_metric('system_health', default=100, unit='%')\n",
    "        \n",
    "        # Agent actions affect resources\n",
    "        for agent in updated.agents:\n",
    "            if agent.activity == 'generate_power':\n",
    "                power.value = min(100, float(power.value) + 15)\n",
    "            elif agent.activity == 'research':\n",
    "                research.value = min(100, float(research.value) + 10)\n",
    "                power.value = max(0, float(power.value) - 8)  # Research uses power\n",
    "            elif agent.activity == 'maintenance':\n",
    "                maintenance.value = min(100, float(maintenance.value) + 12)\n",
    "        \n",
    "        # Natural degradation each tick\n",
    "        power.value = max(0, float(power.value) - 5)  # Base consumption\n",
    "        maintenance.value = max(0, float(maintenance.value) - 3)  # Systems degrade\n",
    "        \n",
    "        updated.tick = tick\n",
    "        return updated\n",
    "    \n",
    "    def validate_action(self, action, state):\n",
    "        return True  # Accept all actions for this simple example\n",
    "\n",
    "print('‚úÖ Mars habitat physics defined')\n",
    "print('\\nPhysics rules:')\n",
    "print('   Action effects:')\n",
    "print('   ‚Ä¢ generate_power: +15 kWh')\n",
    "print('   ‚Ä¢ research: +10% progress, -8 kWh')\n",
    "print('   ‚Ä¢ maintenance: +12% system health')\n",
    "print('\\n   Natural degradation:')\n",
    "print('   ‚Ä¢ Power: -5 kWh per tick (base consumption)')\n",
    "print('   ‚Ä¢ System health: -3% per tick (wear and tear)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create the World State\n",
    "\n",
    "The world state defines the starting conditions:\n",
    "- Initial resource levels (power at 60%, research at 25%, systems at 70%)\n",
    "- Which agents exist in the simulation\n",
    "- Environment configuration (we're using abstract tier for this simple example)\n",
    "\n",
    "We're starting with a challenging situation - power and systems both below optimal levels!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ World state initialized\n",
      "\n",
      "Initial conditions:\n",
      "   Tick: 0\n",
      "\n",
      "   Resources:\n",
      "   ‚ö†Ô∏è Power Reserve: 60kWh\n",
      "   ‚úÖ Research Progress: 25%\n",
      "   ‚ö†Ô∏è System Health: 70%\n",
      "\n",
      "   Agents:\n",
      "   ‚Ä¢ Commander Liu (id: commander)\n",
      "   ‚Ä¢ Engineer Kim (id: engineer)\n",
      "   ‚Ä¢ Dr. Patel (id: scientist)\n",
      "\n",
      "   Challenge: Power and system health need attention!\n"
     ]
    }
   ],
   "source": [
    "world_state = WorldState(\n",
    "    tick=0,\n",
    "    timestamp=datetime.now(timezone.utc),\n",
    "    environment=EnvironmentState(metrics={}),\n",
    "    resources=ResourceState(metrics={\n",
    "        'power': Stat(value=60, unit='kWh', label='Power Reserve'),\n",
    "        'research_progress': Stat(value=25, unit='%', label='Research Progress'),\n",
    "        'system_health': Stat(value=70, unit='%', label='System Health')\n",
    "    }),\n",
    "    agents=[\n",
    "        AgentStatus(agent_id='commander', display_name='Commander Liu'),\n",
    "        AgentStatus(agent_id='engineer', display_name='Engineer Kim'),\n",
    "        AgentStatus(agent_id='scientist', display_name='Dr. Patel')\n",
    "    ]\n",
    ")\n",
    "\n",
    "print('‚úÖ World state initialized')\n",
    "print('\\nInitial conditions:')\n",
    "print(f'   Tick: {world_state.tick}')\n",
    "print('\\n   Resources:')\n",
    "for key, stat in world_state.resources.metrics.items():\n",
    "    status = '‚ö†Ô∏è' if (key == 'power' and stat.value < 80) or (key == 'system_health' and stat.value < 80) else '‚úÖ'\n",
    "    print(f'   {status} {stat.label}: {stat.value}{stat.unit}')\n",
    "print('\\n   Agents:')\n",
    "for agent in world_state.agents:\n",
    "    print(f'   ‚Ä¢ {agent.display_name} (id: {agent.agent_id})')\n",
    "print('\\n   Challenge: Power and system health need attention!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Define Agent Profiles\n",
    "\n",
    "Each agent has:\n",
    "- **Identity** - name, age, background\n",
    "- **Role** - their job on the Mars base\n",
    "- **Personality** - how they approach decisions\n",
    "- **Skills** - what they're good at\n",
    "- **Goals** - what they're trying to achieve\n",
    "- **Relationships** - how they relate to other agents\n",
    "\n",
    "These profiles inform the LLM's decision-making - agents act according to their character!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Agent profiles created\n",
      "\n",
      "=== Meet the Crew ===\n",
      "\n",
      "üë§ Commander Liu\n",
      "   Role: mission_commander\n",
      "   Age: 42\n",
      "   Personality: strategic, calm under pressure, prioritizes crew safety\n",
      "   Skills: leadership, decision_making\n",
      "   Goals:\n",
      "     ‚Ä¢ Ensure crew safety\n",
      "     ‚Ä¢ Complete mission objectives\n",
      "     ‚Ä¢ Maintain team morale\n",
      "   Relationships:\n",
      "     ‚Ä¢ Engineer Kim: trusts technical judgment\n",
      "     ‚Ä¢ Dr. Patel: values research input\n",
      "\n",
      "üë§ Engineer Kim\n",
      "   Role: systems_engineer\n",
      "   Age: 35\n",
      "   Personality: detail-oriented, proactive, safety-focused\n",
      "   Skills: systems, power_management, maintenance\n",
      "   Goals:\n",
      "     ‚Ä¢ Keep systems operational\n",
      "     ‚Ä¢ Optimize power usage\n",
      "     ‚Ä¢ Prevent failures\n",
      "   Relationships:\n",
      "     ‚Ä¢ Commander Liu: reports to\n",
      "     ‚Ä¢ Dr. Patel: coordinates with\n",
      "\n",
      "üë§ Dr. Patel\n",
      "   Role: lead_scientist\n",
      "   Age: 38\n",
      "   Personality: curious, methodical, mission-driven\n",
      "   Skills: research, analysis\n",
      "   Goals:\n",
      "     ‚Ä¢ Advance Mars research\n",
      "     ‚Ä¢ Make discoveries\n",
      "     ‚Ä¢ Publish findings\n",
      "   Relationships:\n",
      "     ‚Ä¢ Commander Liu: collaborates with\n",
      "     ‚Ä¢ Engineer Kim: relies on for equipment\n"
     ]
    }
   ],
   "source": [
    "agents = {\n",
    "    'commander': AgentProfile(\n",
    "        agent_id='commander',\n",
    "        name='Commander Liu',\n",
    "        age=42,\n",
    "        background='15 years military + 5 years NASA mission experience',\n",
    "        role='mission_commander',\n",
    "        personality='strategic, calm under pressure, prioritizes crew safety',\n",
    "        skills={'leadership': 'expert', 'decision_making': 'expert'},\n",
    "        goals=['Ensure crew safety', 'Complete mission objectives', 'Maintain team morale'],\n",
    "        relationships={'engineer': 'trusts technical judgment', 'scientist': 'values research input'}\n",
    "    ),\n",
    "    'engineer': AgentProfile(\n",
    "        agent_id='engineer',\n",
    "        name='Engineer Kim',\n",
    "        age=35,\n",
    "        background='Aerospace engineer, 8 years ISS systems experience',\n",
    "        role='systems_engineer',\n",
    "        personality='detail-oriented, proactive, safety-focused',\n",
    "        skills={'systems': 'expert', 'power_management': 'expert', 'maintenance': 'expert'},\n",
    "        goals=['Keep systems operational', 'Optimize power usage', 'Prevent failures'],\n",
    "        relationships={'commander': 'reports to', 'scientist': 'coordinates with'}\n",
    "    ),\n",
    "    'scientist': AgentProfile(\n",
    "        agent_id='scientist',\n",
    "        name='Dr. Patel',\n",
    "        age=38,\n",
    "        background='Astrobiologist, 10 years Mars research',\n",
    "        role='lead_scientist',\n",
    "        personality='curious, methodical, mission-driven',\n",
    "        skills={'research': 'expert', 'analysis': 'expert'},\n",
    "        goals=['Advance Mars research', 'Make discoveries', 'Publish findings'],\n",
    "        relationships={'commander': 'collaborates with', 'engineer': 'relies on for equipment'}\n",
    "    )\n",
    "}\n",
    "\n",
    "print('‚úÖ Agent profiles created')\n",
    "print('\\n=== Meet the Crew ===')\n",
    "for agent_id, profile in agents.items():\n",
    "    print(f'\\nüë§ {profile.name}')\n",
    "    print(f'   Role: {profile.role}')\n",
    "    print(f'   Age: {profile.age}')\n",
    "    print(f'   Personality: {profile.personality}')\n",
    "    print(f'   Skills: {\", \".join(f\"{k}\" for k in profile.skills.keys())}')\n",
    "    print(f'   Goals:')\n",
    "    for goal in profile.goals:\n",
    "        print(f'     ‚Ä¢ {goal}')\n",
    "    print(f'   Relationships:')\n",
    "    for other, rel in profile.relationships.items():\n",
    "        other_name = agents[other].name if other in agents else other\n",
    "        print(f'     ‚Ä¢ {other_name}: {rel}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Configure Agent Cognition\n",
    "\n",
    "This is where the LLM magic happens! Each agent gets a **cognition bundle**:\n",
    "\n",
    "- **Executor** - Makes immediate decisions (\"What action should I take right now?\")\n",
    "- **Planner** - Creates multi-step plans (\"What's my agenda for the day?\")\n",
    "- **Scratchpad** - Working memory for tracking commitments and state\n",
    "\n",
    "We're using `LLMExecutor` and `LLMPlanner`, which call your configured LLM to make intelligent, context-aware decisions.\n",
    "\n",
    "We also give each agent **role instructions** - these are injected into the LLM prompts to guide their behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Agent cognition configured\n",
      "\n",
      "=== Cognition Architecture ===\n",
      "\n",
      "Each agent has:\n",
      "   üß† LLMExecutor - Makes immediate action decisions via LLM\n",
      "   üìã LLMPlanner - Generates multi-step plans via LLM\n",
      "   üìù Scratchpad - Working memory for state tracking\n",
      "\n",
      "Agent instructions configured:\n",
      "   ‚Ä¢ Commander Liu: You are Commander Liu on a Mars habitat.\n",
      "   ‚Ä¢ Engineer Kim: You are Engineer Kim maintaining Mars habitat systems.\n",
      "   ‚Ä¢ Dr. Patel: You are Dr. Patel, lead scientist on Mars.\n"
     ]
    }
   ],
   "source": [
    "# Create cognition modules for each agent\n",
    "cognition_map = {\n",
    "    'commander': AgentCognition(\n",
    "        executor=LLMExecutor(),\n",
    "        planner=LLMPlanner(),\n",
    "        scratchpad=Scratchpad()\n",
    "    ),\n",
    "    'engineer': AgentCognition(\n",
    "        executor=LLMExecutor(),\n",
    "        planner=LLMPlanner(),\n",
    "        scratchpad=Scratchpad()\n",
    "    ),\n",
    "    'scientist': AgentCognition(\n",
    "        executor=LLMExecutor(),\n",
    "        planner=LLMPlanner(),\n",
    "        scratchpad=Scratchpad()\n",
    "    )\n",
    "}\n",
    "\n",
    "# Role-specific instructions (injected into LLM prompts)\n",
    "agent_prompts = {\n",
    "    'commander': '''You are Commander Liu on a Mars habitat.\n",
    "\n",
    "Your responsibilities:\n",
    "- Oversee base operations and crew coordination\n",
    "- Make strategic decisions about priorities\n",
    "- Communicate with team via brief updates\n",
    "\n",
    "Available actions: generate_power, research, maintenance, coordinate, rest\n",
    "\n",
    "Current priorities: Safety > Systems > Research''',\n",
    "    \n",
    "    'engineer': '''You are Engineer Kim maintaining Mars habitat systems.\n",
    "\n",
    "Your responsibilities:\n",
    "- Monitor power levels and system health\n",
    "- Perform maintenance when needed\n",
    "- Generate power when reserves are low\n",
    "- Advise commander on technical issues\n",
    "\n",
    "Available actions: generate_power, maintenance, rest\n",
    "\n",
    "Keep power above 40 kWh and systems above 60%.''',\n",
    "    \n",
    "    'scientist': '''You are Dr. Patel, lead scientist on Mars.\n",
    "\n",
    "Your responsibilities:\n",
    "- Conduct research experiments\n",
    "- Balance research with base needs\n",
    "- Communicate findings and coordinate with crew\n",
    "\n",
    "Available actions: research, rest\n",
    "\n",
    "Research is important but requires power - coordinate with engineer.'''\n",
    "}\n",
    "\n",
    "print('‚úÖ Agent cognition configured')\n",
    "print('\\n=== Cognition Architecture ===')\n",
    "print('\\nEach agent has:')\n",
    "print('   üß† LLMExecutor - Makes immediate action decisions via LLM')\n",
    "print('   üìã LLMPlanner - Generates multi-step plans via LLM')\n",
    "print('   üìù Scratchpad - Working memory for state tracking')\n",
    "print('\\nAgent instructions configured:')\n",
    "for agent_id in agent_prompts:\n",
    "    agent_name = agents[agent_id].name\n",
    "    lines = agent_prompts[agent_id].strip().split('\\n')\n",
    "    print(f'   ‚Ä¢ {agent_name}: {lines[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Run the Simulation\n",
    "\n",
    "Now we bring it all together with the **Orchestrator**.\n",
    "\n",
    "Each tick, the orchestrator:\n",
    "1. Applies physics rules (resources change)\n",
    "2. Agents observe the world\n",
    "3. Agents plan/decide using LLMs\n",
    "4. Agents take actions\n",
    "5. Actions are processed\n",
    "6. Memories are stored\n",
    "\n",
    "Let's run 5 ticks and watch the agents coordinate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting Mars habitat simulation...\n",
      "   Provider: openai\n",
      "   Model: gpt-5-nano\n",
      "   Duration: 5 ticks\n",
      "\n",
      "Watch agents coordinate to manage power, research, and maintenance!\n",
      "============================================================\n",
      "Starting simulation run b3b5ab65-e4eb-4833-a3b6-64667770c39b\n",
      "Agents: 3, Ticks: 5\n",
      "\n",
      "=== Tick 1/5 ===\n",
      "  [Physics] Applying deterministic rules for tick 1...\n",
      "  [Physics] ‚úì Physics applied\n",
      "  [Commander Liu] Building perception...\n",
      "  [Engineer Kim] Building perception...\n",
      "  [Dr. Patel] Building perception...\n",
      "  [Engineer Kim] Choosing action via executor...\n",
      "  [Commander Liu] Choosing action via executor...\n",
      "  [Dr. Patel] Choosing action via executor...\n",
      "  [Engineer Kim] ‚úì Got action: work\n",
      "LLM schema validation failed for AgentAction (attempt 1/3).\n",
      "    - communication: Input should be a valid dictionary [type=dict_type] | received=\"Hi Kim, coordinating power optimization to ensure sufficient power for a 60-...\n",
      "LLM retry 2/3 for AgentAction; attempting schema correction.\n",
      "  [Commander Liu] ‚úì Got action: communicate\n",
      "  [Dr. Patel] ‚úì Got action: communicate\n",
      "  [World Engine] Processing 3 actions...\n",
      "  [World Engine] ‚úì World state updated\n",
      "  [Persistence] Persisting tick 1...\n",
      "ERROR at tick 1: 1 validation error for AgentMemory\n",
      "importance\n",
      "  Input should be a valid integer [type=int_type, input_value=None, input_type=NoneType]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/int_type\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for AgentMemory\nimportance\n  Input should be a valid integer [type=int_type, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.12/v/int_type",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mWatch agents coordinate to manage power, research, and maintenance!\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33m=\u001b[39m\u001b[33m'\u001b[39m * \u001b[32m60\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m orchestrator.run(num_ticks=\u001b[32m5\u001b[39m)\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33m=\u001b[39m\u001b[33m'\u001b[39m * \u001b[32m60\u001b[39m)\n\u001b[32m     23\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m‚úÖ Simulation complete!\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/lab/miniverse/miniverse/orchestrator.py:175\u001b[39m, in \u001b[36mOrchestrator.run\u001b[39m\u001b[34m(self, num_ticks)\u001b[39m\n\u001b[32m    172\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m=== Tick \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtick\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_ticks\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._run_tick(tick)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    177\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mERROR at tick \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtick\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/lab/miniverse/miniverse/orchestrator.py:233\u001b[39m, in \u001b[36mOrchestrator._run_tick\u001b[39m\u001b[34m(self, tick)\u001b[39m\n\u001b[32m    228\u001b[39m new_state = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_world_update(tick, actions)\n\u001b[32m    230\u001b[39m \u001b[38;5;66;03m# 3. Persist tick data (state, actions, memories) to backend. Persistence happens\u001b[39;00m\n\u001b[32m    231\u001b[39m \u001b[38;5;66;03m# AFTER the world engine succeeds so we never save partial/corrupt data. Memory\u001b[39;00m\n\u001b[32m    232\u001b[39m \u001b[38;5;66;03m# creation includes reflection engine invocations for agents that hit their cadence.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m233\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._persist_tick(tick, new_state, actions)\n\u001b[32m    235\u001b[39m \u001b[38;5;66;03m# 4. Print human-readable summary for monitoring. Shows resource levels, agent actions,\u001b[39;00m\n\u001b[32m    236\u001b[39m \u001b[38;5;66;03m# and recent events. Helps users understand simulation progress without reading logs.\u001b[39;00m\n\u001b[32m    237\u001b[39m \u001b[38;5;28mself\u001b[39m._print_tick_summary(tick, actions, new_state)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/lab/miniverse/miniverse/orchestrator.py:508\u001b[39m, in \u001b[36mOrchestrator._persist_tick\u001b[39m\u001b[34m(self, tick, state, actions)\u001b[39m\n\u001b[32m    506\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.persistence.save_state(\u001b[38;5;28mself\u001b[39m.run_id, tick, state)\n\u001b[32m    507\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.persistence.save_actions(\u001b[38;5;28mself\u001b[39m.run_id, tick, actions)\n\u001b[32m--> \u001b[39m\u001b[32m508\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._update_memories(tick, actions, state)\n\u001b[32m    509\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  [Persistence] ‚úì Tick \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtick\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m persisted\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/lab/miniverse/miniverse/orchestrator.py:566\u001b[39m, in \u001b[36mOrchestrator._update_memories\u001b[39m\u001b[34m(self, tick, actions, state)\u001b[39m\n\u001b[32m    564\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m event.tick == tick:  \u001b[38;5;66;03m# Only new events\u001b[39;00m\n\u001b[32m    565\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m agent_id \u001b[38;5;129;01min\u001b[39;00m event.affected_agents:\n\u001b[32m--> \u001b[39m\u001b[32m566\u001b[39m             memory = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.memory.add_memory(\n\u001b[32m    567\u001b[39m                 run_id=\u001b[38;5;28mself\u001b[39m.run_id,\n\u001b[32m    568\u001b[39m                 agent_id=agent_id,\n\u001b[32m    569\u001b[39m                 tick=tick,\n\u001b[32m    570\u001b[39m                 memory_type=\u001b[33m\"\u001b[39m\u001b[33mobservation\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    571\u001b[39m                 content=event.description,\n\u001b[32m    572\u001b[39m                 importance=event.severity,\n\u001b[32m    573\u001b[39m                 tags=[\n\u001b[32m    574\u001b[39m                     \u001b[33m\"\u001b[39m\u001b[33mevent\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    575\u001b[39m                     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mseverity:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent.severity\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event.severity \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mseverity:unknown\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    576\u001b[39m                     event.category,\n\u001b[32m    577\u001b[39m                 ],\n\u001b[32m    578\u001b[39m                 metadata={\n\u001b[32m    579\u001b[39m                     \u001b[33m\"\u001b[39m\u001b[33mevent_id\u001b[39m\u001b[33m\"\u001b[39m: event.event_id,\n\u001b[32m    580\u001b[39m                     \u001b[33m\"\u001b[39m\u001b[33mcategory\u001b[39m\u001b[33m\"\u001b[39m: event.category,\n\u001b[32m    581\u001b[39m                 },\n\u001b[32m    582\u001b[39m             )\n\u001b[32m    583\u001b[39m             new_memories.setdefault(agent_id, []).append(memory)\n\u001b[32m    585\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._run_reflections(tick, new_memories)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/lab/miniverse/miniverse/memory.py:257\u001b[39m, in \u001b[36mSimpleMemoryStream.add_memory\u001b[39m\u001b[34m(self, run_id, agent_id, tick, memory_type, content, importance, tags, metadata, embedding_key, branch_id)\u001b[39m\n\u001b[32m    234\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    235\u001b[39m \u001b[33;03mAdd a memory to the stream.\u001b[39;00m\n\u001b[32m    236\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    253\u001b[39m \u001b[33;03m    The created AgentMemory object\u001b[39;00m\n\u001b[32m    254\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    255\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01muuid\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m memory = \u001b[43mAgentMemory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43muuid\u001b[49m\u001b[43m.\u001b[49m\u001b[43muuid4\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m    \u001b[49m\u001b[43magent_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43magent_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtick\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmemory_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimportance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimportance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtags\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbranch_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbranch_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreated_at\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdatetime\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.persistence.save_memory(run_id, memory)\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m memory\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/lab/miniverse/.venv/lib/python3.13/site-packages/pydantic/main.py:250\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    249\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    252\u001b[39m     warnings.warn(\n\u001b[32m    253\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    254\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    255\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    256\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    257\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for AgentMemory\nimportance\n  Input should be a valid integer [type=int_type, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.12/v/int_type"
     ]
    }
   ],
   "source": [
    "# Create and configure orchestrator\n",
    "orchestrator = Orchestrator(\n",
    "    world_state=world_state,\n",
    "    agents=agents,\n",
    "    world_prompt='',\n",
    "    agent_prompts=agent_prompts,\n",
    "    simulation_rules=MarsHabitatRules(),\n",
    "    agent_cognition=cognition_map,\n",
    "    llm_provider=provider,\n",
    "    llm_model=model\n",
    ")\n",
    "\n",
    "print('üöÄ Starting Mars habitat simulation...')\n",
    "print(f'   Provider: {provider}')\n",
    "print(f'   Model: {model}')\n",
    "print(f'   Duration: 5 ticks')\n",
    "print('\\nWatch agents coordinate to manage power, research, and maintenance!')\n",
    "print('=' * 60)\n",
    "\n",
    "result = await orchestrator.run(num_ticks=5)\n",
    "\n",
    "print('=' * 60)\n",
    "print('\\n‚úÖ Simulation complete!')\n",
    "print(f'   Run ID: {result[\"run_id\"]}')\n",
    "print(f'   Final tick: {result[\"final_state\"].tick}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Inspect the Results\n",
    "\n",
    "Let's see how the world changed during the simulation.\n",
    "\n",
    "We'll compare initial vs final resource levels and see what each agent ended up doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SIMULATION RESULTS ===\n",
      "\n",
      "Ticks elapsed: 5\n",
      "\n",
      "--- Resource Changes ---\n",
      "\n",
      "Power Reserve:\n",
      "   Initial: 60kWh\n",
      "   Final:   34.0kWh\n",
      "   Change:  ‚Üì 26.0kWh\n",
      "\n",
      "Research Progress:\n",
      "   Initial: 25%\n",
      "   Final:   36%\n",
      "   Change:  ‚Üë 11.0%\n",
      "\n",
      "System Health:\n",
      "   Initial: 70%\n",
      "   Final:   65.0%\n",
      "   Change:  ‚Üì 5.0%\n",
      "\n",
      "--- Final Agent Activities ---\n",
      "   ‚Ä¢ Commander Liu: finalizing crew briefing and assigning tasks; roles confirmed within 25-minute window\n",
      "   ‚Ä¢ Engineer Kim: performing proactive maintenance on power_subsystems; stabilizing power reserve; load management readiness\n",
      "   ‚Ä¢ Dr. Patel: synthesizing Mars soil data findings; research progress updated to 36%\n"
     ]
    }
   ],
   "source": [
    "final = result['final_state']\n",
    "\n",
    "print('=== SIMULATION RESULTS ===')\n",
    "print(f'\\nTicks elapsed: {final.tick}')\n",
    "\n",
    "print('\\n--- Resource Changes ---')\n",
    "for key in ['power', 'research_progress', 'system_health']:\n",
    "    initial = world_state.resources.metrics[key]\n",
    "    final_stat = final.resources.metrics[key]\n",
    "    change = float(final_stat.value) - float(initial.value)\n",
    "    arrow = '‚Üë' if change > 0 else '‚Üì' if change < 0 else '‚Üí'\n",
    "    print(f'\\n{final_stat.label}:')\n",
    "    print(f'   Initial: {initial.value}{initial.unit}')\n",
    "    print(f'   Final:   {final_stat.value}{final_stat.unit}')\n",
    "    print(f'   Change:  {arrow} {abs(change):.1f}{final_stat.unit}')\n",
    "\n",
    "print('\\n--- Final Agent Activities ---')\n",
    "for agent in final.agents:\n",
    "    agent_profile = agents[agent.agent_id]\n",
    "    print(f'   ‚Ä¢ {agent.display_name}: {agent.activity or \"idle\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Peek Under the Hood - Agent Reasoning\n",
    "\n",
    "The magic of Miniverse is **full observability**. Let's inspect what agents were thinking!\n",
    "\n",
    "We can retrieve actions from any tick and see:\n",
    "- What action the agent chose\n",
    "- Why they chose it (LLM reasoning)\n",
    "- What they communicated to others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AGENT REASONING (Tick 5) ===\n",
      "\n",
      "What were agents thinking in the final tick?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_id = result['run_id']\n",
    "\n",
    "# Get actions from final tick\n",
    "final_tick = final.tick\n",
    "tick_actions = await orchestrator.persistence.get_actions(run_id, tick=final_tick)\n",
    "\n",
    "print(f'=== AGENT REASONING (Tick {final_tick}) ===')\n",
    "print('\\nWhat were agents thinking in the final tick?\\n')\n",
    "\n",
    "if not tick_actions:\n",
    "    print('‚ö†Ô∏è  No actions found for this tick.')\n",
    "    print('   (This might happen if actions weren\\'t saved during the simulation)')\n",
    "else:\n",
    "    for action in tick_actions:\n",
    "        agent_name = agents[action.agent_id].name\n",
    "        print(f'ü§ñ {agent_name}')\n",
    "        print(f'   Action: {action.action_type}')\n",
    "        print(f'   Reasoning: {action.reasoning}')\n",
    "        if action.communication:\n",
    "            # communication is a Dict with message content\n",
    "            if isinstance(action.communication, dict):\n",
    "                msg = action.communication.get('message', str(action.communication))\n",
    "                print(f'   üí¨ Communication: \"{msg}\"')\n",
    "            else:\n",
    "                print(f'   üí¨ Communication: \"{action.communication}\"')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Inspect Agent Memories\n",
    "\n",
    "Agents remember what they observe each tick. These memories inform future decisions.\n",
    "\n",
    "Let's look at what the Engineer remembers - did they notice the power crisis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get engineer's memories (last 10)\n",
    "engineer_memories = await orchestrator.persistence.get_recent_memories(\n",
    "    run_id, \n",
    "    agent_id='engineer',\n",
    "    limit=10\n",
    ")\n",
    "\n",
    "print(f'=== ENGINEER\\'S MEMORY LOG ===')\n",
    "print(f'\\nTotal memories retrieved: {len(engineer_memories)}')\n",
    "\n",
    "if not engineer_memories:\n",
    "    print('\\n‚ö†Ô∏è  No memories found for this agent.')\n",
    "    print('   (Memories are created as agents observe the world each tick)')\n",
    "else:\n",
    "    print(f'\\nRecent observations (last {min(5, len(engineer_memories))}):\\n')\n",
    "    \n",
    "    # Show most recent 5\n",
    "    for i, mem in enumerate(list(reversed(engineer_memories))[:5], 1):\n",
    "        print(f'{i}. [Tick {mem.tick}]')\n",
    "        # Truncate long memories for readability\n",
    "        content = mem.content if len(mem.content) <= 120 else mem.content[:120] + '...'\n",
    "        print(f'   {content}')\n",
    "        if mem.tags:\n",
    "            print(f'   Tags: {\", \".join(mem.tags)}')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Action Statistics\n",
    "\n",
    "Let's analyze what actions agents took across all ticks.\n",
    "\n",
    "This shows us the emergent behavior - how did agents coordinate without explicit teamwork code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "# Get all actions across all ticks\n",
    "all_actions = []\n",
    "for tick in range(1, final.tick + 1):\n",
    "    tick_actions = await orchestrator.persistence.get_actions(run_id, tick=tick)\n",
    "    all_actions.extend(tick_actions)\n",
    "\n",
    "print('=== ACTION STATISTICS ===')\n",
    "print(f'\\nTotal actions: {len(all_actions)}')\n",
    "\n",
    "# Actions by agent\n",
    "agent_actions = defaultdict(list)\n",
    "for action in all_actions:\n",
    "    agent_actions[action.agent_id].append(action.action_type)\n",
    "\n",
    "print('\\n--- Actions by Agent ---')\n",
    "for agent_id, action_list in agent_actions.items():\n",
    "    agent_name = agents[agent_id].name\n",
    "    action_counts = Counter(action_list)\n",
    "    print(f'\\n{agent_name}:')\n",
    "    for action_type, count in action_counts.most_common():\n",
    "        print(f'   ‚Ä¢ {action_type}: {count}x')\n",
    "\n",
    "# Communication stats\n",
    "communications = [a for a in all_actions if a.communication]\n",
    "print(f'\\n--- Communication ---')\n",
    "print(f'Messages sent: {len(communications)}')\n",
    "if communications:\n",
    "    print('\\nSample messages:')\n",
    "    for i, action in enumerate(communications[:3], 1):\n",
    "        agent_name = agents[action.agent_id].name\n",
    "        msg = action.communication[:80] + '...' if len(action.communication) > 80 else action.communication\n",
    "        print(f'   {i}. {agent_name}: \"{msg}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí° What You Just Saw\n",
    "\n",
    "**Miniverse simulated 5 hours on Mars with 3 LLM-powered agents**\n",
    "\n",
    "### Each Tick:\n",
    "1. ‚öôÔ∏è **Physics applied** - power drained, systems degraded, actions took effect\n",
    "2. üëÅÔ∏è **Agents observed** - saw resource levels, other agents' activities\n",
    "3. üß† **Agents planned** - LLM generated multi-step plans based on role and situation\n",
    "4. ‚úÖ **Agents acted** - chose actions aligned with plans and goals\n",
    "5. üíæ **Memories stored** - observations saved for future reasoning\n",
    "\n",
    "### Key Features:\n",
    "- **Emergent coordination** - no hardcoded teamwork, agents adapted based on situation\n",
    "- **LLM reasoning** - decisions explained in natural language\n",
    "- **Memory persistence** - agents remember past events\n",
    "- **Full observability** - inspect plans, memories, reasoning at any point\n",
    "\n",
    "### The Setup (Core Pattern):\n",
    "```python\n",
    "# 1. Define physics (SimulationRules subclass)\n",
    "class MarsHabitatRules(SimulationRules):\n",
    "    def apply_tick(self, state, tick):\n",
    "        # Your domain logic here\n",
    "        return updated_state\n",
    "\n",
    "# 2. Create agents with profiles\n",
    "agents = {\"commander\": AgentProfile(...), ...}\n",
    "\n",
    "# 3. Configure cognition (LLM-powered)\n",
    "cognition = {\"commander\": AgentCognition(\n",
    "    executor=LLMExecutor(),\n",
    "    planner=LLMPlanner()\n",
    ")}\n",
    "\n",
    "# 4. Run simulation\n",
    "orchestrator = Orchestrator(...)\n",
    "result = await orchestrator.run(num_ticks=5)\n",
    "```\n",
    "\n",
    "**That's it!** Physics + profiles + cognition = emergent behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Next Steps\n",
    "\n",
    "### Explore More Examples\n",
    "- **`tutorial.ipynb`** - Reference guide for all primitives (Stat, Plan, Memory, etc.)\n",
    "- **`examples/workshop/`** - Progressive examples:\n",
    "  - `01_hello_world` - Simplest possible simulation\n",
    "  - `02_deterministic` - Threshold-based logic (no LLM)\n",
    "  - `03_llm_single` - Single LLM agent\n",
    "  - `04_team_chat` - Multi-agent communication\n",
    "  - `05_stochastic` - Random events + LLM adaptation\n",
    "\n",
    "### Build Your Own Simulation\n",
    "1. **Define physics** - subclass `SimulationRules`\n",
    "2. **Create agents** - profiles with goals and relationships\n",
    "3. **Choose cognition** - deterministic, LLM, or hybrid\n",
    "4. **Run and observe** - inspect emergent behavior\n",
    "\n",
    "### Common Use Cases\n",
    "- Social simulations (Stanford Generative Agents style)\n",
    "- Multi-agent systems research\n",
    "- Game AI and NPC behavior\n",
    "- Organizational dynamics\n",
    "- Economic modeling\n",
    "\n",
    "### What Makes Miniverse Special\n",
    "- ‚úÖ **Deterministic physics** - controllable, predictable rules\n",
    "- ‚úÖ **Emergent cognition** - LLM-driven intelligence\n",
    "- ‚úÖ **Full observability** - inspect everything\n",
    "- ‚úÖ **Modular design** - swap strategies easily\n",
    "- ‚úÖ **Production-ready** - persistence, memory, planning all built-in\n",
    "\n",
    "---\n",
    "\n",
    "**Ready to build something?** Check out `docs/USAGE.md` for detailed guides!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Miniverse (uv)",
   "language": "python",
   "name": "miniverse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
