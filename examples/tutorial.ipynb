{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miniverse Tutorial: Building Agent-Based Simulations from Scratch\n",
    "\n",
    "This notebook teaches you how to use Miniverse by building up from basic primitives to full simulations.\n",
    "\n",
    "**What you'll learn:**\n",
    "- Core data structures (AgentProfile, WorldState, Plan, Scratchpad, Memory)\n",
    "- Cognition modules (Executor, Planner, ReflectionEngine)\n",
    "- Building simulations step-by-step\n",
    "- Understanding what's happening \"under the hood\"\n",
    "\n",
    "**Prerequisites:**\n",
    "- Python 3.10+\n",
    "- Miniverse installed (`uv sync`)\n",
    "- Optional: LLM API key for later sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Core Primitives - Data Structures\n",
    "\n",
    "Before running any simulation, let's understand the basic building blocks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 The Stat Object - Flexible Metrics\n",
    "\n",
    "`Stat` is the basic unit for representing any numeric value with metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Energy stat:\n",
      "  Value: 80\n",
      "  Unit: %\n",
      "  Label: Energy Level\n",
      "\n",
      "Backlog: 15 Task Backlog\n",
      "Temperature: 22.5°C\n"
     ]
    }
   ],
   "source": [
    "from miniverse import Stat\n",
    "\n",
    "# Create different types of stats\n",
    "energy = Stat(value=80, unit=\"%\", label=\"Energy Level\")\n",
    "backlog = Stat(value=15, label=\"Task Backlog\")\n",
    "temperature = Stat(value=22.5, unit=\"°C\", label=\"Room Temperature\")\n",
    "\n",
    "print(\"Energy stat:\")\n",
    "print(f\"  Value: {energy.value}\")\n",
    "print(f\"  Unit: {energy.unit}\")\n",
    "print(f\"  Label: {energy.label}\")\n",
    "print(f\"\\nBacklog: {backlog.value} {backlog.label}\")\n",
    "print(f\"Temperature: {temperature.value}{temperature.unit}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 AgentProfile - Who is this agent?\n",
    "\n",
    "Every agent has a profile describing their identity, personality, and goals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent Profile:\n",
      "  ID: alice\n",
      "  Name: Alice, Age: 28\n",
      "  Role: developer\n",
      "  Personality: friendly and detail-oriented\n",
      "  Background: Software engineer who loves collaborative work\n",
      "  Skills: {'python': 'expert', 'teamwork': 'proficient'}\n",
      "  Goals: ['Write clean code', 'Help teammates', 'Maintain work-life balance']\n",
      "  Relationships: {'bob': 'colleague'}\n"
     ]
    }
   ],
   "source": [
    "from miniverse import AgentProfile\n",
    "\n",
    "# Create an agent profile\n",
    "alice = AgentProfile(\n",
    "    agent_id=\"alice\",\n",
    "    name=\"Alice\",\n",
    "    age=28,\n",
    "    background=\"Software engineer who loves collaborative work\",\n",
    "    role=\"developer\",\n",
    "    personality=\"friendly and detail-oriented\",\n",
    "    skills={\"python\": \"expert\", \"teamwork\": \"proficient\"},\n",
    "    goals=[\"Write clean code\", \"Help teammates\", \"Maintain work-life balance\"],\n",
    "    relationships={\"bob\": \"colleague\"}\n",
    ")\n",
    "\n",
    "print(\"Agent Profile:\")\n",
    "print(f\"  ID: {alice.agent_id}\")\n",
    "print(f\"  Name: {alice.name}, Age: {alice.age}\")\n",
    "print(f\"  Role: {alice.role}\")\n",
    "print(f\"  Personality: {alice.personality}\")\n",
    "print(f\"  Background: {alice.background}\")\n",
    "print(f\"  Skills: {alice.skills}\")\n",
    "print(f\"  Goals: {alice.goals}\")\n",
    "print(f\"  Relationships: {alice.relationships}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 AgentStatus - Current state of an agent\n",
    "\n",
    "While `AgentProfile` describes WHO the agent is, `AgentStatus` tracks their CURRENT state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent Status (Current State):\n",
      "  Agent: Alice (Developer)\n",
      "  Activity: coding\n",
      "  Location: office_2b\n",
      "  Attributes:\n",
      "    - Energy: 75%\n",
      "    - Focus: 85%\n",
      "    - Happiness: 70%\n"
     ]
    }
   ],
   "source": [
    "from miniverse import AgentStatus\n",
    "\n",
    "# Create agent status (what's happening RIGHT NOW)\n",
    "alice_status = AgentStatus(\n",
    "    agent_id=\"alice\",\n",
    "    display_name=\"Alice (Developer)\",\n",
    "    activity=\"coding\",\n",
    "    location=\"office_2b\",\n",
    "    attributes={\n",
    "        \"energy\": Stat(value=75, unit=\"%\", label=\"Energy\"),\n",
    "        \"focus\": Stat(value=85, unit=\"%\", label=\"Focus\"),\n",
    "        \"happiness\": Stat(value=70, unit=\"%\", label=\"Happiness\")\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Agent Status (Current State):\")\n",
    "print(f\"  Agent: {alice_status.display_name}\")\n",
    "print(f\"  Activity: {alice_status.activity}\")\n",
    "print(f\"  Location: {alice_status.location}\")\n",
    "print(f\"  Attributes:\")\n",
    "for key, stat in alice_status.attributes.items():\n",
    "    print(f\"    - {stat.label}: {stat.value}{stat.unit or ''}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 WorldState - The complete simulation state\n",
    "\n",
    "`WorldState` contains everything: resources, environment, and all agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World State:\n",
      "  Tick: 0\n",
      "  Timestamp: 2025-10-16 00:10:28.413400+00:00\n",
      "\n",
      "  Environment:\n",
      "    - Room Temperature: 22.0°C\n",
      "\n",
      "  Resources:\n",
      "    - Tasks Pending: 10 \n",
      "    - Coffee Remaining: 5 cups\n",
      "\n",
      "  Agents: 1\n",
      "    - Alice (Developer) (coding)\n"
     ]
    }
   ],
   "source": [
    "from miniverse import WorldState, ResourceState, EnvironmentState\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# Create a simple world state\n",
    "world = WorldState(\n",
    "    tick=0,\n",
    "    timestamp=datetime.now(timezone.utc),\n",
    "    environment=EnvironmentState(\n",
    "        metrics={\n",
    "            \"temperature\": Stat(value=22.0, unit=\"°C\", label=\"Room Temperature\")\n",
    "        }\n",
    "    ),\n",
    "    resources=ResourceState(\n",
    "        metrics={\n",
    "            \"task_backlog\": Stat(value=10, label=\"Tasks Pending\"),\n",
    "            \"coffee\": Stat(value=5, unit=\"cups\", label=\"Coffee Remaining\")\n",
    "        }\n",
    "    ),\n",
    "    agents=[alice_status]\n",
    ")\n",
    "\n",
    "print(\"World State:\")\n",
    "print(f\"  Tick: {world.tick}\")\n",
    "print(f\"  Timestamp: {world.timestamp}\")\n",
    "print(f\"\\n  Environment:\")\n",
    "for key, stat in world.environment.metrics.items():\n",
    "    print(f\"    - {stat.label}: {stat.value}{stat.unit or ''}\")\n",
    "print(f\"\\n  Resources:\")\n",
    "for key, stat in world.resources.metrics.items():\n",
    "    print(f\"    - {stat.label}: {stat.value} {stat.unit or ''}\")\n",
    "print(f\"\\n  Agents: {len(world.agents)}\")\n",
    "for agent in world.agents:\n",
    "    print(f\"    - {agent.display_name} ({agent.activity})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Plan - Multi-step agent plans\n",
    "\n",
    "Agents can have plans with multiple steps. Let's see what a plan looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent Plan:\n",
      "  Total steps: 4\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Plan' object has no attribute 'current_step_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAgent Plan:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Total steps: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(morning_plan.steps)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Current step: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mmorning_plan\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcurrent_step_index\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m  Steps:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(morning_plan.steps):\n",
      "\u001b[31mAttributeError\u001b[39m: 'Plan' object has no attribute 'current_step_index'"
     ]
    }
   ],
   "source": [
    "from miniverse.cognition import Plan, PlanStep\n",
    "\n",
    "# Create a multi-step plan\n",
    "morning_plan = Plan(\n",
    "    steps=[\n",
    "        PlanStep(description=\"Review overnight alerts\", metadata={\"duration\": 1}),\n",
    "        PlanStep(description=\"Work on feature implementation\", metadata={\"duration\":\n",
    "3}),\n",
    "        PlanStep(description=\"Code review for teammate\", metadata={\"duration\": 1}),\n",
    "        PlanStep(description=\"Take lunch break\", metadata={\"duration\": 1})\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Agent Plan:\")\n",
    "print(f\"  Total steps: {len(morning_plan.steps)}\")\n",
    "print(f\"\\n  Steps:\")\n",
    "for i, step in enumerate(morning_plan.steps):\n",
    "    duration = step.metadata.get(\"duration\", \"?\")\n",
    "    marker = \"→\" if i == 0 else \" \"  # First step is current\n",
    "    print(f\"    {marker} Step {i}: {step.description} ({duration} ticks)\")\n",
    "\n",
    "print(f\"\\nNote: Plan progress is tracked by the orchestrator in scratchpad.\")\n",
    "print(f\"The orchestrator advances through steps automatically.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Scratchpad - Working memory\n",
    "\n",
    "The scratchpad is a simple key-value store for agents to track temporary state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from miniverse.cognition import Scratchpad\n",
    "\n",
    "# Create a scratchpad and use it\n",
    "scratchpad = Scratchpad()\n",
    "\n",
    "# Store various working memory items\n",
    "scratchpad.state[\"last_break\"] = 5  # tick number\n",
    "scratchpad.state[\"current_task\"] = \"implement_authentication\"\n",
    "scratchpad.state[\"blockers\"] = [\"waiting for API key\", \"database schema unclear\"]\n",
    "scratchpad.state[\"energy_trend\"] = \"declining\"\n",
    "\n",
    "print(\"Scratchpad (Working Memory):\")\n",
    "for key, value in scratchpad.state.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Access specific values\n",
    "print(f\"\\nLast break was at tick: {scratchpad.state.get('last_break')}\")\n",
    "print(f\"Current blockers: {scratchpad.state.get('blockers')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 AgentMemory - Long-term memory entries\n",
    "\n",
    "Memories have importance scores, tags, and timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from miniverse import AgentMemory\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# Create some memory entries\n",
    "memories = [\n",
    "    AgentMemory(\n",
    "        agent_id=\"alice\",\n",
    "        tick=5,\n",
    "        timestamp=datetime.now(timezone.utc),\n",
    "        content=\"Helped Bob debug a tricky concurrency issue. He seemed grateful.\",\n",
    "        memory_type=\"observation\",\n",
    "        importance=7,\n",
    "        tags=[\"collaboration\", \"teamwork\", \"technical\"]\n",
    "    ),\n",
    "    AgentMemory(\n",
    "        agent_id=\"alice\",\n",
    "        tick=8,\n",
    "        timestamp=datetime.now(timezone.utc),\n",
    "        content=\"Feeling energized after completing the authentication feature.\",\n",
    "        memory_type=\"observation\",\n",
    "        importance=5,\n",
    "        tags=[\"achievement\", \"energy\"]\n",
    "    ),\n",
    "    AgentMemory(\n",
    "        agent_id=\"alice\",\n",
    "        tick=10,\n",
    "        timestamp=datetime.now(timezone.utc),\n",
    "        content=\"I've been helping teammates a lot - this aligns with my goal of collaboration.\",\n",
    "        memory_type=\"reflection\",\n",
    "        importance=8,\n",
    "        tags=[\"reflection\", \"goals\", \"teamwork\"]\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"Agent Memories:\")\n",
    "for i, memory in enumerate(memories, 1):\n",
    "    print(f\"\\n  Memory {i} (Tick {memory.tick}):\")\n",
    "    print(f\"    Type: {memory.memory_type}\")\n",
    "    print(f\"    Importance: {memory.importance}/10\")\n",
    "    print(f\"    Tags: {', '.join(memory.tags)}\")\n",
    "    print(f\"    Content: \\\"{memory.content}\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Cognition Modules\n",
    "\n",
    "Now let's explore the modules that power agent decision-making."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Executor - The decision-maker\n",
    "\n",
    "Every agent needs an executor to choose actions. Let's build a simple one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from miniverse import AgentAction, Perception\n",
    "\n",
    "# Define a simple executor\n",
    "class AlwaysWorkExecutor:\n",
    "    \"\"\"Simplest possible executor - always chooses 'work'.\"\"\"\n",
    "    \n",
    "    async def choose_action(self, agent_id, perception, scratchpad, *, plan, plan_step, context):\n",
    "        return AgentAction(\n",
    "            agent_id=agent_id,\n",
    "            tick=perception.tick,\n",
    "            action_type=\"work\",\n",
    "            reasoning=\"I always work - it's hardcoded!\"\n",
    "        )\n",
    "\n",
    "# Test it\n",
    "executor = AlwaysWorkExecutor()\n",
    "\n",
    "# Create a mock perception\n",
    "mock_perception = Perception(\n",
    "    tick=1,\n",
    "    agent_id=\"alice\",\n",
    "    visible_resources={\"task_backlog\": Stat(value=10)},\n",
    "    personal_attributes={\"energy\": Stat(value=80, unit=\"%\")},\n",
    "    nearby_agents=[],\n",
    "    recent_messages=[]\n",
    ")\n",
    "\n",
    "# Get action\n",
    "import asyncio\n",
    "action = await executor.choose_action(\n",
    "    agent_id=\"alice\",\n",
    "    perception=mock_perception,\n",
    "    scratchpad=None,\n",
    "    plan=None,\n",
    "    plan_step=None,\n",
    "    context={}\n",
    ")\n",
    "\n",
    "print(\"Executor Output:\")\n",
    "print(f\"  Agent: {action.agent_id}\")\n",
    "print(f\"  Action: {action.action_type}\")\n",
    "print(f\"  Reasoning: {action.reasoning}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 A smarter executor - Threshold logic\n",
    "\n",
    "Let's build an executor that makes decisions based on agent state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThresholdExecutor:\n",
    "    \"\"\"Makes decisions based on energy and backlog thresholds.\"\"\"\n",
    "    \n",
    "    async def choose_action(self, agent_id, perception, scratchpad, *, plan, plan_step, context):\n",
    "        # Extract current state\n",
    "        energy_stat = perception.personal_attributes.get(\"energy\")\n",
    "        energy = float(energy_stat.value) if energy_stat else 100\n",
    "        \n",
    "        backlog_stat = perception.visible_resources.get(\"task_backlog\")\n",
    "        backlog = float(backlog_stat.value) if backlog_stat else 0\n",
    "        \n",
    "        # Decision logic\n",
    "        if energy < 30:\n",
    "            action_type = \"rest\"\n",
    "            reasoning = f\"Energy low ({energy}%) - need to rest\"\n",
    "        elif backlog > 8:\n",
    "            action_type = \"work\"\n",
    "            reasoning = f\"High backlog ({int(backlog)} tasks) - must work\"\n",
    "        else:\n",
    "            action_type = \"rest\"\n",
    "            reasoning = f\"Energy {energy}%, backlog {int(backlog)} - resting\"\n",
    "        \n",
    "        return AgentAction(\n",
    "            agent_id=agent_id,\n",
    "            tick=perception.tick,\n",
    "            action_type=action_type,\n",
    "            reasoning=reasoning\n",
    "        )\n",
    "\n",
    "# Test with different states\n",
    "executor = ThresholdExecutor()\n",
    "\n",
    "test_cases = [\n",
    "    {\"energy\": 80, \"backlog\": 10, \"desc\": \"High energy, high backlog\"},\n",
    "    {\"energy\": 25, \"backlog\": 10, \"desc\": \"Low energy, high backlog\"},\n",
    "    {\"energy\": 80, \"backlog\": 3, \"desc\": \"High energy, low backlog\"},\n",
    "]\n",
    "\n",
    "print(\"Threshold Executor Tests:\\n\")\n",
    "for case in test_cases:\n",
    "    perception = Perception(\n",
    "        tick=1,\n",
    "        agent_id=\"alice\",\n",
    "        visible_resources={\"task_backlog\": Stat(value=case[\"backlog\"])},\n",
    "        personal_attributes={\"energy\": Stat(value=case[\"energy\"], unit=\"%\")},\n",
    "        nearby_agents=[],\n",
    "        recent_messages=[]\n",
    "    )\n",
    "    \n",
    "    action = await executor.choose_action(\n",
    "        agent_id=\"alice\",\n",
    "        perception=perception,\n",
    "        scratchpad=None,\n",
    "        plan=None,\n",
    "        plan_step=None,\n",
    "        context={}\n",
    "    )\n",
    "    \n",
    "    print(f\"  {case['desc']}:\")\n",
    "    print(f\"    → Action: {action.action_type}\")\n",
    "    print(f\"    → Reasoning: {action.reasoning}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 AgentCognition - Bundling modules together\n",
    "\n",
    "The `AgentCognition` object bundles executor, planner, reflection, and scratchpad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from miniverse.cognition import AgentCognition\n",
    "\n",
    "# Minimal cognition: just executor\n",
    "cognition_minimal = AgentCognition(\n",
    "    executor=ThresholdExecutor()\n",
    ")\n",
    "\n",
    "print(\"Minimal Cognition:\")\n",
    "print(f\"  Executor: {type(cognition_minimal.executor).__name__}\")\n",
    "print(f\"  Planner: {cognition_minimal.planner}\")\n",
    "print(f\"  Reflection: {cognition_minimal.reflection}\")\n",
    "print(f\"  Scratchpad: {cognition_minimal.scratchpad}\")\n",
    "\n",
    "# Cognition with scratchpad\n",
    "cognition_with_memory = AgentCognition(\n",
    "    executor=ThresholdExecutor(),\n",
    "    scratchpad=Scratchpad()\n",
    ")\n",
    "\n",
    "print(\"\\nCognition with Scratchpad:\")\n",
    "print(f\"  Executor: {type(cognition_with_memory.executor).__name__}\")\n",
    "print(f\"  Scratchpad: {type(cognition_with_memory.scratchpad).__name__}\")\n",
    "\n",
    "# Store something in scratchpad\n",
    "cognition_with_memory.scratchpad.state[\"test_key\"] = \"test_value\"\n",
    "print(f\"  Scratchpad state: {cognition_with_memory.scratchpad.state}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: First Simulation - Putting it together\n",
    "\n",
    "Let's run our first actual simulation with all the pieces we've learned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Define physics (SimulationRules)\n",
    "\n",
    "Physics determine how the world changes each tick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from miniverse import SimulationRules, WorldState, AgentAction\n",
    "\n",
    "class SimpleWorkshopRules(SimulationRules):\n",
    "    \"\"\"Basic workshop physics: working drains energy, resting recovers it.\"\"\"\n",
    "    \n",
    "    def apply_tick(self, state: WorldState, tick: int) -> WorldState:\n",
    "        # Make a deep copy to avoid mutating original\n",
    "        updated = state.model_copy(deep=True)\n",
    "        \n",
    "        # Update each agent based on their activity\n",
    "        for agent in updated.agents:\n",
    "            energy = agent.get_attribute(\"energy\", default=80, unit=\"%\")\n",
    "            \n",
    "            if agent.activity == \"work\":\n",
    "                energy.value = max(0.0, float(energy.value) - 10)  # Working drains energy\n",
    "            else:  # resting\n",
    "                energy.value = min(100.0, float(energy.value) + 15)  # Resting recovers energy\n",
    "        \n",
    "        updated.tick = tick\n",
    "        return updated\n",
    "    \n",
    "    def validate_action(self, action: AgentAction, state: WorldState) -> bool:\n",
    "        # Accept all actions for this simple example\n",
    "        return True\n",
    "\n",
    "print(\"Physics defined: SimpleWorkshopRules\")\n",
    "print(\"  - Working drains 10 energy per tick\")\n",
    "print(\"  - Resting recovers 15 energy per tick\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Set up the simulation\n",
    "\n",
    "Now we'll create agents, cognition, and the orchestrator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from miniverse import Orchestrator, AgentProfile, AgentStatus, WorldState, ResourceState, EnvironmentState\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# Create agent profile\n",
    "alice_profile = AgentProfile(\n",
    "    agent_id=\"alice\",\n",
    "    name=\"Alice\",\n",
    "    age=28,\n",
    "    background=\"Workshop technician\",\n",
    "    role=\"worker\",\n",
    "    personality=\"diligent and thoughtful\",\n",
    "    skills={\"task_management\": \"proficient\"},\n",
    "    goals=[\"Maintain energy\", \"Complete tasks\"],\n",
    "    relationships={}\n",
    ")\n",
    "\n",
    "# Create initial world state\n",
    "initial_state = WorldState(\n",
    "    tick=0,\n",
    "    timestamp=datetime.now(timezone.utc),\n",
    "    environment=EnvironmentState(metrics={}),\n",
    "    resources=ResourceState(\n",
    "        metrics={\n",
    "            \"task_backlog\": Stat(value=12, label=\"Task Backlog\")\n",
    "        }\n",
    "    ),\n",
    "    agents=[\n",
    "        AgentStatus(\n",
    "            agent_id=\"alice\",\n",
    "            display_name=\"Alice\",\n",
    "            attributes={\"energy\": Stat(value=80, unit=\"%\", label=\"Energy\")}\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create cognition with scratchpad so we can see state\n",
    "alice_cognition = AgentCognition(\n",
    "    executor=ThresholdExecutor(),\n",
    "    scratchpad=Scratchpad()\n",
    ")\n",
    "\n",
    "# Create orchestrator\n",
    "orchestrator = Orchestrator(\n",
    "    world_state=initial_state,\n",
    "    agents={\"alice\": alice_profile},\n",
    "    world_prompt=\"\",\n",
    "    agent_prompts={\"alice\": \"You are Alice, a workshop worker.\"},\n",
    "    simulation_rules=SimpleWorkshopRules(),\n",
    "    agent_cognition={\"alice\": alice_cognition}\n",
    ")\n",
    "\n",
    "print(\"Simulation ready!\")\n",
    "print(f\"  Agents: 1 (Alice)\")\n",
    "print(f\"  Physics: SimpleWorkshopRules\")\n",
    "print(f\"  Cognition: ThresholdExecutor with Scratchpad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Run the simulation and inspect each tick\n",
    "\n",
    "Let's run 5 ticks and see what happens at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run simulation\n",
    "result = await orchestrator.run(num_ticks=5)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SIMULATION COMPLETE - Let's examine what happened\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get final state\n",
    "final_state = result[\"final_state\"]\n",
    "alice_final = next(a for a in final_state.agents if a.agent_id == \"alice\")\n",
    "\n",
    "print(f\"\\nFinal tick: {final_state.tick}\")\n",
    "print(f\"Alice's final energy: {alice_final.get_attribute('energy').value}%\")\n",
    "print(f\"Alice's final activity: {alice_final.activity}\")\n",
    "\n",
    "# Show scratchpad state if any\n",
    "print(f\"\\nScratchpad state: {alice_cognition.scratchpad.state}\")\n",
    "\n",
    "print(\"\\nKey observations:\")\n",
    "print(\"  - Each tick, physics was applied first (energy changed)\")\n",
    "print(\"  - Then executor decided what to do (work or rest)\")\n",
    "print(\"  - Action affected next tick's state\")\n",
    "print(\"  - This is the core simulation loop!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Examine tick-by-tick state transitions\n",
    "\n",
    "Let's run again and manually inspect each tick's state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset simulation\n",
    "initial_state = WorldState(\n",
    "    tick=0,\n",
    "    timestamp=datetime.now(timezone.utc),\n",
    "    environment=EnvironmentState(metrics={}),\n",
    "    resources=ResourceState(\n",
    "        metrics={\"task_backlog\": Stat(value=12, label=\"Task Backlog\")}\n",
    "    ),\n",
    "    agents=[\n",
    "        AgentStatus(\n",
    "            agent_id=\"alice\",\n",
    "            display_name=\"Alice\",\n",
    "            attributes={\"energy\": Stat(value=80, unit=\"%\", label=\"Energy\")}\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "alice_cognition = AgentCognition(\n",
    "    executor=ThresholdExecutor(),\n",
    "    scratchpad=Scratchpad()\n",
    ")\n",
    "\n",
    "orchestrator = Orchestrator(\n",
    "    world_state=initial_state,\n",
    "    agents={\"alice\": alice_profile},\n",
    "    world_prompt=\"\",\n",
    "    agent_prompts={\"alice\": \"You are Alice.\"},\n",
    "    simulation_rules=SimpleWorkshopRules(),\n",
    "    agent_cognition={\"alice\": alice_cognition}\n",
    ")\n",
    "\n",
    "# Run tick by tick\n",
    "print(\"\\nTick-by-tick state transitions:\\n\")\n",
    "\n",
    "for tick in range(1, 6):\n",
    "    result = await orchestrator.run(num_ticks=1)\n",
    "    state = result[\"final_state\"]\n",
    "    alice = next(a for a in state.agents if a.agent_id == \"alice\")\n",
    "    energy = alice.get_attribute(\"energy\").value\n",
    "    backlog = state.resources.get_metric(\"task_backlog\").value\n",
    "    \n",
    "    print(f\"Tick {tick}:\")\n",
    "    print(f\"  Energy: {energy}%\")\n",
    "    print(f\"  Backlog: {int(backlog)} tasks\")\n",
    "    print(f\"  Activity: {alice.activity}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Adding LLM Intelligence\n",
    "\n",
    "Now let's replace our threshold executor with an LLM that makes intelligent decisions.\n",
    "\n",
    "**Note:** This requires LLM configuration (API keys)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Check if LLM is configured\n",
    "provider = os.getenv(\"LLM_PROVIDER\")\n",
    "model = os.getenv(\"LLM_MODEL\")\n",
    "\n",
    "if provider and model:\n",
    "    print(f\"✓ LLM configured: {provider}/{model}\")\n",
    "    print(\"  We can proceed with LLM examples\")\n",
    "else:\n",
    "    print(\"✗ LLM not configured\")\n",
    "    print(\"\\nTo use LLM examples, set:\")\n",
    "    print(\"  export LLM_PROVIDER=openai\")\n",
    "    print(\"  export LLM_MODEL=gpt-4\")\n",
    "    print(\"  export OPENAI_API_KEY=your_key\")\n",
    "    print(\"\\nSkipping LLM examples for now...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 LLM Executor - Context-aware decisions\n",
    "\n",
    "Let's see what context the LLM receives and how it decides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run if LLM is configured\n",
    "if provider and model:\n",
    "    from miniverse.cognition import LLMExecutor\n",
    "    \n",
    "    # Create LLM-powered cognition\n",
    "    alice_llm_cognition = AgentCognition(\n",
    "        executor=LLMExecutor(),\n",
    "        scratchpad=Scratchpad()\n",
    "    )\n",
    "    \n",
    "    # Create simulation with LLM executor\n",
    "    initial_state = WorldState(\n",
    "        tick=0,\n",
    "        timestamp=datetime.now(timezone.utc),\n",
    "        environment=EnvironmentState(metrics={}),\n",
    "        resources=ResourceState(\n",
    "            metrics={\"task_backlog\": Stat(value=12, label=\"Task Backlog\")}\n",
    "        ),\n",
    "        agents=[\n",
    "            AgentStatus(\n",
    "                agent_id=\"alice\",\n",
    "                display_name=\"Alice\",\n",
    "                attributes={\"energy\": Stat(value=80, unit=\"%\", label=\"Energy\")}\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    orchestrator_llm = Orchestrator(\n",
    "        world_state=initial_state,\n",
    "        agents={\"alice\": alice_profile},\n",
    "        world_prompt=\"\",\n",
    "        agent_prompts={\n",
    "            \"alice\": \"\"\"You are Alice, a thoughtful workshop worker.\n",
    "            \n",
    "Your goals:\n",
    "- Maintain your wellbeing (don't let energy drop too low)\n",
    "- Address the task backlog when it's high\n",
    "- Balance productivity and self-care\n",
    "\n",
    "Available actions: work, rest\"\"\"\n",
    "        },\n",
    "        simulation_rules=SimpleWorkshopRules(),\n",
    "        agent_cognition={\"alice\": alice_llm_cognition},\n",
    "        llm_provider=provider,\n",
    "        llm_model=model\n",
    "    )\n",
    "    \n",
    "    print(\"Running 3 ticks with LLM executor...\\n\")\n",
    "    result = await orchestrator_llm.run(num_ticks=3)\n",
    "    \n",
    "    final = result[\"final_state\"]\n",
    "    alice = next(a for a in final.agents if a.agent_id == \"alice\")\n",
    "    \n",
    "    print(f\"\\nLLM simulation complete:\")\n",
    "    print(f\"  Final energy: {alice.get_attribute('energy').value}%\")\n",
    "    print(f\"  Final activity: {alice.activity}\")\n",
    "    print(f\"\\nNotice: LLM makes nuanced decisions, not just threshold-based!\")\n",
    "else:\n",
    "    print(\"Skipping LLM example (not configured)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Memory and Persistence\n",
    "\n",
    "Let's examine how memories accumulate and how to inspect them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Accessing memories from persistence\n",
    "\n",
    "By default, Miniverse uses in-memory persistence. Let's inspect what's stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the simulation ID from last run\n",
    "sim_id = result[\"simulation_id\"]\n",
    "print(f\"Simulation ID: {sim_id}\")\n",
    "\n",
    "# Access persistence (in-memory by default)\n",
    "persistence = orchestrator.persistence\n",
    "\n",
    "# Get all memories for Alice\n",
    "alice_memories = await persistence.get_memories(sim_id, agent_id=\"alice\")\n",
    "\n",
    "print(f\"\\nAlice has {len(alice_memories)} memories:\")\n",
    "for i, memory in enumerate(alice_memories[:5], 1):  # Show first 5\n",
    "    print(f\"\\n  Memory {i} (Tick {memory.tick}):\")\n",
    "    print(f\"    Type: {memory.memory_type}\")\n",
    "    print(f\"    Importance: {memory.importance}\")\n",
    "    print(f\"    Content: \\\"{memory.content[:80]}...\\\" if len(memory.content) > 80 else memory.content\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Understanding memory retrieval\n",
    "\n",
    "The `MemoryStrategy` controls how agents retrieve relevant memories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from miniverse.memory import SimpleMemoryStream\n",
    "\n",
    "# Create a memory stream\n",
    "memory_stream = SimpleMemoryStream()\n",
    "\n",
    "# Simulate some memories\n",
    "test_memories = [\n",
    "    AgentMemory(\n",
    "        agent_id=\"alice\",\n",
    "        tick=1,\n",
    "        timestamp=datetime.now(timezone.utc),\n",
    "        content=\"Started working on authentication feature\",\n",
    "        memory_type=\"observation\",\n",
    "        importance=5,\n",
    "        tags=[\"work\", \"coding\"]\n",
    "    ),\n",
    "    AgentMemory(\n",
    "        agent_id=\"alice\",\n",
    "        tick=2,\n",
    "        timestamp=datetime.now(timezone.utc),\n",
    "        content=\"Helped Bob debug a tricky issue - felt good to collaborate\",\n",
    "        memory_type=\"observation\",\n",
    "        importance=7,\n",
    "        tags=[\"collaboration\", \"teamwork\", \"Bob\"]\n",
    "    ),\n",
    "    AgentMemory(\n",
    "        agent_id=\"alice\",\n",
    "        tick=3,\n",
    "        timestamp=datetime.now(timezone.utc),\n",
    "        content=\"Energy getting low, need a break soon\",\n",
    "        memory_type=\"observation\",\n",
    "        importance=6,\n",
    "        tags=[\"energy\", \"wellbeing\"]\n",
    "    ),\n",
    "    AgentMemory(\n",
    "        agent_id=\"alice\",\n",
    "        tick=5,\n",
    "        timestamp=datetime.now(timezone.utc),\n",
    "        content=\"I've been balancing work and rest well - staying productive without burning out\",\n",
    "        memory_type=\"reflection\",\n",
    "        importance=8,\n",
    "        tags=[\"reflection\", \"balance\", \"goals\"]\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Retrieve relevant memories for a query\n",
    "query = \"How is my energy doing?\"\n",
    "relevant = memory_stream.get_relevant_memories(\n",
    "    memories=test_memories,\n",
    "    query=query,\n",
    "    limit=3\n",
    ")\n",
    "\n",
    "print(f\"Query: '{query}'\")\n",
    "print(f\"\\nRelevant memories (top 3):\")\n",
    "for i, memory in enumerate(relevant, 1):\n",
    "    print(f\"\\n  {i}. (Tick {memory.tick}, importance {memory.importance}):\")\n",
    "    print(f\"     \\\"{memory.content}\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Planning - Multi-step reasoning\n",
    "\n",
    "Now let's add planning capability to agents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Create a simple deterministic planner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from miniverse.cognition import Plan, PlanStep\n",
    "\n",
    "class DailyRoutinePlanner:\n",
    "    \"\"\"Creates a fixed daily routine plan.\"\"\"\n",
    "    \n",
    "    async def generate_plan(self, agent_id, agent_profile, world_state, recent_memories, *, context):\n",
    "        # Create a simple 4-step plan\n",
    "        plan = Plan(\n",
    "            steps=[\n",
    "                PlanStep(description=\"Morning check-in and review tasks\", metadata={\"duration\": 1}),\n",
    "                PlanStep(description=\"Work on high-priority tasks\", metadata={\"duration\": 3}),\n",
    "                PlanStep(description=\"Take lunch break and rest\", metadata={\"duration\": 1}),\n",
    "                PlanStep(description=\"Afternoon work session\", metadata={\"duration\": 2}),\n",
    "            ],\n",
    "            current_step_index=0\n",
    "        )\n",
    "        return plan, \"Daily routine plan\"\n",
    "\n",
    "# Test it\n",
    "planner = DailyRoutinePlanner()\n",
    "plan, reasoning = await planner.generate_plan(\n",
    "    agent_id=\"alice\",\n",
    "    agent_profile=alice_profile,\n",
    "    world_state=initial_state,\n",
    "    recent_memories=[],\n",
    "    context={}\n",
    ")\n",
    "\n",
    "print(\"Generated Plan:\")\n",
    "print(f\"  Reasoning: {reasoning}\")\n",
    "print(f\"  Total steps: {len(plan.steps)}\")\n",
    "print(f\"\\n  Steps:\")\n",
    "for i, step in enumerate(plan.steps):\n",
    "    duration = step.metadata.get(\"duration\", \"?\")\n",
    "    print(f\"    {i}. {step.description} ({duration} ticks)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Run simulation with planning\n",
    "\n",
    "Let's see how plans guide agent behavior over multiple ticks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create executor that follows plan\n",
    "class PlanFollowerExecutor:\n",
    "    \"\"\"Executor that follows the current plan step.\"\"\"\n",
    "    \n",
    "    async def choose_action(self, agent_id, perception, scratchpad, *, plan, plan_step, context):\n",
    "        if plan_step:\n",
    "            # We have a plan - follow it\n",
    "            if \"work\" in plan_step.description.lower():\n",
    "                action_type = \"work\"\n",
    "            elif \"break\" in plan_step.description.lower() or \"rest\" in plan_step.description.lower():\n",
    "                action_type = \"rest\"\n",
    "            else:\n",
    "                action_type = \"work\"  # Default\n",
    "            \n",
    "            reasoning = f\"Following plan: {plan_step.description}\"\n",
    "        else:\n",
    "            # No plan - fall back to simple logic\n",
    "            action_type = \"rest\"\n",
    "            reasoning = \"No plan - resting\"\n",
    "        \n",
    "        return AgentAction(\n",
    "            agent_id=agent_id,\n",
    "            tick=perception.tick,\n",
    "            action_type=action_type,\n",
    "            reasoning=reasoning\n",
    "        )\n",
    "\n",
    "# Create cognition with planner\n",
    "alice_planned_cognition = AgentCognition(\n",
    "    executor=PlanFollowerExecutor(),\n",
    "    planner=DailyRoutinePlanner(),\n",
    "    scratchpad=Scratchpad()\n",
    ")\n",
    "\n",
    "# Run simulation\n",
    "initial_state = WorldState(\n",
    "    tick=0,\n",
    "    timestamp=datetime.now(timezone.utc),\n",
    "    environment=EnvironmentState(metrics={}),\n",
    "    resources=ResourceState(\n",
    "        metrics={\"task_backlog\": Stat(value=10, label=\"Task Backlog\")}\n",
    "    ),\n",
    "    agents=[\n",
    "        AgentStatus(\n",
    "            agent_id=\"alice\",\n",
    "            display_name=\"Alice\",\n",
    "            attributes={\"energy\": Stat(value=100, unit=\"%\", label=\"Energy\")}\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "orchestrator_planned = Orchestrator(\n",
    "    world_state=initial_state,\n",
    "    agents={\"alice\": alice_profile},\n",
    "    world_prompt=\"\",\n",
    "    agent_prompts={\"alice\": \"You follow your daily routine plan.\"},\n",
    "    simulation_rules=SimpleWorkshopRules(),\n",
    "    agent_cognition={\"alice\": alice_planned_cognition}\n",
    ")\n",
    "\n",
    "print(\"Running 7 ticks with planner...\\n\")\n",
    "result = await orchestrator_planned.run(num_ticks=7)\n",
    "\n",
    "print(\"\\nSimulation with planning complete!\")\n",
    "print(\"\\nKey insight: Agent followed multi-step plan across ticks\")\n",
    "print(\"  - Plan persisted in scratchpad\")\n",
    "print(\"  - Executor used current plan step to decide actions\")\n",
    "print(\"  - Plan advanced automatically each tick\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Reflection - Learning from experience\n",
    "\n",
    "Reflection engines analyze accumulated memories and generate insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Simple heuristic reflection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleReflection:\n",
    "    \"\"\"Heuristic reflection: detects patterns in memories.\"\"\"\n",
    "    \n",
    "    async def maybe_reflect(\n",
    "        self,\n",
    "        agent_id,\n",
    "        agent_profile,\n",
    "        recent_memories,\n",
    "        world_state,\n",
    "        *,\n",
    "        context\n",
    "    ):\n",
    "        # Only reflect if we have enough memories\n",
    "        if len(recent_memories) < 5:\n",
    "            return []\n",
    "        \n",
    "        # Count \"work\" vs \"rest\" mentions\n",
    "        work_count = sum(1 for m in recent_memories if \"work\" in m.content.lower())\n",
    "        rest_count = sum(1 for m in recent_memories if \"rest\" in m.content.lower())\n",
    "        \n",
    "        reflections = []\n",
    "        \n",
    "        if work_count > rest_count * 2:\n",
    "            reflections.append(\n",
    "                AgentMemory(\n",
    "                    agent_id=agent_id,\n",
    "                    tick=world_state.tick,\n",
    "                    timestamp=datetime.now(timezone.utc),\n",
    "                    content=\"I've been working a lot lately - might need more rest to avoid burnout.\",\n",
    "                    memory_type=\"reflection\",\n",
    "                    importance=8,\n",
    "                    tags=[\"reflection\", \"balance\", \"wellbeing\"]\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        return reflections\n",
    "\n",
    "# Test reflection\n",
    "test_memories = [\n",
    "    AgentMemory(agent_id=\"alice\", tick=i, timestamp=datetime.now(timezone.utc),\n",
    "                content=\"Worked on tasks\" if i % 2 == 0 else \"Took a break\",\n",
    "                memory_type=\"observation\", importance=5, tags=[])\n",
    "    for i in range(10)\n",
    "]\n",
    "\n",
    "reflector = SimpleReflection()\n",
    "reflections = await reflector.maybe_reflect(\n",
    "    agent_id=\"alice\",\n",
    "    agent_profile=alice_profile,\n",
    "    recent_memories=test_memories,\n",
    "    world_state=initial_state,\n",
    "    context={}\n",
    ")\n",
    "\n",
    "print(\"Reflection Analysis:\")\n",
    "print(f\"  Analyzed {len(test_memories)} memories\")\n",
    "print(f\"  Generated {len(reflections)} reflections\")\n",
    "if reflections:\n",
    "    for reflection in reflections:\n",
    "        print(f\"\\n  Reflection:\")\n",
    "        print(f\"    Content: \\\"{reflection.content}\\\"\")\n",
    "        print(f\"    Importance: {reflection.importance}\")\n",
    "        print(f\"    Tags: {reflection.tags}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: What we've learned\n",
    "\n",
    "You now understand:\n",
    "\n",
    "**Data Structures:**\n",
    "- `Stat` - Flexible metrics with units/labels\n",
    "- `AgentProfile` - WHO the agent is (identity, personality, goals)\n",
    "- `AgentStatus` - CURRENT state (activity, location, attributes)\n",
    "- `WorldState` - Complete simulation state\n",
    "- `Plan` - Multi-step plans with duration\n",
    "- `Scratchpad` - Working memory (key-value store)\n",
    "- `AgentMemory` - Long-term memories with importance/tags\n",
    "\n",
    "**Cognition Modules:**\n",
    "- `Executor` - Required: chooses actions each tick\n",
    "- `Planner` - Optional: generates multi-step plans\n",
    "- `ReflectionEngine` - Optional: synthesizes insights from memories\n",
    "- `AgentCognition` - Bundles modules together\n",
    "\n",
    "**Simulation Mechanics:**\n",
    "- `SimulationRules` - Deterministic physics (world updates)\n",
    "- `Orchestrator` - Main simulation loop\n",
    "- Tick loop: Physics → Plan → Perceive → Execute → Update\n",
    "\n",
    "**Design Patterns:**\n",
    "- Minimal: `AgentCognition(executor=MyExecutor())`\n",
    "- With planning: Add `planner` and `scratchpad`\n",
    "- With reflection: Add `reflection` engine\n",
    "- LLM-driven: Use `LLMExecutor`, `LLMPlanner`, `LLMReflectionEngine`\n",
    "\n",
    "**Next steps:**\n",
    "- Explore the workshop examples (01-05) in `examples/workshop/`\n",
    "- Try LLM-powered agents (configure API keys)\n",
    "- Build your own simulation domain\n",
    "- Experiment with custom executors, planners, physics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
